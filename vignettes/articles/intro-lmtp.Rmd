---
title: "Getting Started with LMTP"
output: rmarkdown::html_vignette
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  results = "hold"
)
```

<style type="text/css">
.table {

    width: 50%;
    margin: 0 auto;  

}
</style>

__Authors__: [Nick Williams](https://nicholastwilliams.com) and [Ivan Diaz](https://idiaz.xyz)  
__Updated__: `r Sys.Date()` 

This document serves as an introductory guide to using the `lmtp` package. `lmtp` provides an estimation framework for the causal effects of longitudinal modified treatment policies using ensemble machine learning as described in Diaz, Williams, Hoffman, and Schenck (2020). While originally developed to estimate the effect of continuous exposures, `lmtp` naturally extends to allowing the estimation of traditional causal effects based on binary and categorical exposures in both point treatment and time-varying situations. 

While not possible to cover everything, this introductory guide should equip users of `lmtp` with enough knowledge to handle the majority of use cases. In addition, we assume the analyst has basic knowledge of non-parametric estimation for causal inference; the specifics of the methodology behind the provided functions is not discussed. 

```{r}
library(lmtp)
```

## Functions & parameters

> The goal of this section is to introduce the main `lmtp` functions and develop a basic understanding of required and useful function parameters.

### The estimators

`lmtp` supplies 2 main estimators: 

- a targeted maximum likelihood (TML) estimator: `lmtp_tmle()`
- a sequentially doubly robust (SDR) estimator: `lmtp_sdr()`

Two auxiliary estimators are also provided, however, the use of these estimators is recommended against in favor of the TML or SDR estimators: 

- a G-computation (substitution) estimator: `lmtp_sub()`
- an inverse probability of treatment weighting (IPW) estimator: `lmtp_ipw()`

### Parameter overview

The following table describes `lmtp` parameters across the provided estimators: 

| Parameter        |   TMLE  |   SDR   | Substitution |   IPW   |
|------------------|:-------:|:-------:|:------------:|:-------:|
| data             | &check; | &check; |    &check;   | &check; |
| trt              | &check; | &check; |    &check;   | &check; |
| outcome          | &check; | &check; |    &check;   | &check; |
| baseline         | &check; | &check; |    &check;   | &check; |
| time_vary        | &check; | &check; |    &check;   | &check; |
| cens             | &check; | &check; |    &check;   | &check; |
| k                | &check; | &check; |    &check;   | &check; |
| shift            | &check; | &check; |    &check;   | &check; |
| outcome_type     | &check; | &check; |    &check;   |         |
| bounds           | &check; | &check; |    &check;   |         |
| learners         |         |         |    &check;   | &check; |
| learners_outcome | &check; | &check; |              |         |
| learners_trt     | &check; | &check; |              |         |
| folds            | &check; | &check; |    &check;   | &check; |

<br>

While many parameters aren't required, the default options will likely give sub par (or incorrect) results. Special attention should be given to the `k` parameter which is fully described in the [Node lists & Markov processes] section.

### SuperLearner

### Node lists & Markov processes

> *when in doubt, use `k = Inf`*

Estimating causal effects in longitudinal settings requires paying special attention to the time-ordering and relationships among covariates. In the `lmtp` framework, there are 5 types of variables: treatment, outcome, baseline, time-varying, and censoring. Treatment and outcome variables are self-explanatory, baseline variables are those that are observed pre-treatment allocation, don't change (i.e., age at treatment assignment), and always are used for estimation at all time points, time-varying variables  are variables that (you guessed it...) change over time, censoring nodes indicate if an observation is observed (or censored) at the next time-point.

How these nodes are specified depends on the specific data generating mechanism and should be pre-specified based on a conceptual model (i.e, a DAG). How these nodes are used by `lmtp` estimators is specified by what we call a node list. The analyst doesn't explicitly create the node list themself, but instead supplies the variables and the instructions on how to combine; this is done through the `k` parameter. 

Creating a node list is best understood through demonstration. The following DAG specifies 1 baseline node, `W`, 3 treatment nodes, `A1`, `A2`, `A3`, 3 time-varying nodes, `L1`, `L2`, `L3`, and an outcome, `Y`. 

```{r out.width="80%", echo=FALSE}
knitr::include_graphics("dag-1.png")
```

According to the DAG, `Y` is directly affected by all nodes in the model, `k = Inf` would be the correct instructions for creating this node list. 

```{r}
a <- c("A1", "A2", "A3")
baseline <- c("W")
nodes <- list(c("L1"), 
              c("L2"), 
              c("L3"))

# we can make sure our specification is correct by checking create_node_list()
create_node_list(a, 3, nodes, baseline = baseline, k = Inf)
```

Notice that the time-varying covariates are specified using a list of vectors, allowing the analyst to specify multiple time-varying covariates at each time-point of observation. If provided, the length of this list should be the same length as the treatment vector, `a` in this example (the one exception to this rule is in [Survival analysis]). 

What if we modify the DAG so that `Y` is only directly affected by `A3`, `L3`, and `W`? We could say this data generating mechanism is now a Markov process and the correct `k` would be `k = 0`. 

```{r out.width="80%", echo=FALSE}
knitr::include_graphics("dag-2.png")
```

```{r}
a <- c("A1", "A2", "A3")
baseline <- c("W")
nodes <- list(c("L1"), 
              c("L2"), 
              c("L3"))

# again checking or specification
create_node_list(a, 3, nodes, baseline = baseline, k = 0)
```

Censoring nodes are discussed in the [Censored outcomes] section.

## Calculating effects

> The goal of this section is to identify how to estimate different causal effects using `lmtp` estimators.

### Deterministic causal effects

A deterministic causal effect is the causal effect of any intervention where the exposure level is set deterministically. For example, the average treatment effect considers the difference in population mean outcomes when an exposure or treatment is deterministically applied to everyone versus when it is applied to no one.

### Modified treatment policies

A modified treatment policy is an intervention that can depend on the *natural* value of the exposure. This allows for the formulation of hypothetical interventions that can avoid positivity violations and may be considered feasible. Interested readers are referred to Diaz, Williams, Hoffman, and Schenck (2020) and Haneuse and Rotnitzky (2013), for an overview of modified treatment policies and their advantages compared to deterministic causal effects. 

### Shift functions

To estimate the effect of a deterministic causal intervention or a modified treatment policy with `lmtp` we need to translate these interventions into a shift function. Shift functions are applied to treatment nodes at each time point. They should take 2 arguments, the first being one for the data and the second for the name of the current treatment node. A shift function for a intervention where the exposure decreases by 1 unit for all observations at every time point would look like: 

```{r}
shift <- function(data, trt) {
  data[[trt]] - 1
}
```

We may also be interested in the effect of a modified treatment policy where exposure is decreased by 1 unit only among subjects whose exposure won’t go below 1 if intervened upon:

```{r}
shift <- function(data, trt) {
  (data[[trt]] - 1) * (data[[trt]] - 1 >= 1) + data[[trt]] * (data[[trt]] - 1 < 1)
}
```

Shift functions are passed to lmtp estimators through the `shift` argument. 

```{r}
# using the previous shift function with sdr
a <- c("A_1", "A_2", "A_3", "A_4")
time_varying <- list(c("L_1"), c("L_2"), c("L_3"), c("L_4"))

lmtp_sdr(sim_t4, a, "Y", time_vary = time_varying, k = 0, shift = shift, folds = 5)
```

#### Binary treatment

In the case of a binary treatment/exposure the shift function would simply set treatment/exposure to either 0 or 1 depending on the effect of interest. Two helper shift functions are pre-packaged for this: `static_binary_on()` and `static_binary_off()`.

```{r warning = F}
# a binary trt example
data("iptwExWide", package = "twang")

a <- paste0("tx", 1:3)
nodes <- list(c("gender", "age", "use0"),
              c("use1"), 
              c("use2"))

lmtp_tmle(iptwExWide, a, "outcome", time_vary = nodes, 
          shift = static_binary_on, outcome_type = "continuous",
          folds = 5)
```

### Categorical treatment

To evaluate the effect of an intervention on a categorical exposure, the shift function needs to respect the potential levels of the variable, even when those levels may not be observed. Categorical treatment nodes should be coded as factors and dummy variables should not be created.

```{r}
a <- c("A_1", "A_2", "A_3", "A_4")
time_varying <- list(c("L_1"), c("L_2"), c("L_3"), c("L_4"))

# converting the observed exposures to an ordered factor
sim_t4_fct <- sim_t4
for (i in a) {
  sim_t4_fct[[i]] <- factor(sim_t4[[i]], levels = 0:5, ordered = T)
}

# a shift function that respects that exposure is an ordered factor
shift <- function(data, a) {
    out <- list()
    for (i in 1:length(data[[a]])) {
      if (as.character(data[[a]][i]) %in% c("0", "1")) {
        out[[i]] <- as.character(data[[a]][i])
      } else {
        out[[i]] <- as.numeric(as.character(data[[a]][i])) - 1
      }
    }
    factor(unlist(out), levels = 0:5, ordered = T)
}

lmtp_sdr(sim_t4_fct, a, "Y", time_vary = time_varying, k = 0, shift = shift, folds = 2)
```

### Dynamic treatment regimes

Dynamic treatment regimes are treatment rules where treatment is applied based on a fixed rule that depends on covariate history. `lmtp` is capable of estimating the effects of deterministic dynamic treatment rules as well as dynamic modified treatment policies. 

```{r}
a <- c("A_1", "A_2", "A_3", "A_4")
time_varying <- list(c("L_1"), c("L_2"), c("L_3"), c("L_4"))

# our same shift function
shift <- function(data, trt) {
  (data[[trt]] - 1) * (data[[trt]] - 1 >= 1) + data[[trt]] * (data[[trt]] - 1 < 1)
}

# creating a dynamic mtp that applies the shift function 
# but also depends on history and the current time
dynamic_mtp <- function(data, trt) {
  if (trt == "A_1") {
    # if its the first time point, follow the same mtp as before
    shift(data, trt)
  } else {
    # otherwise check if the time varying covariate equals 1
    ifelse(data[[sub("A", "L", trt)]] == 1, 
           shift(data, trt), # if yes continue with the policy
           data[[trt]]) # otherwise do nothing
  }
}

lmtp_tmle(sim_t4, a, "Y", time_vary = time_varying, k = 0, shift = dynamic_mtp)
```

### Censored outcomes

In the (likely) case of missing outcomes, `lmtp` can estimate the effect of a hypothetical treatment regime where all observations remained uncensored at end of follow-up. To do this, the user must supply a vector containing the names of censoring indicators for each treatment time point to `lmtp` estimators through the `cens` argument. Censoring nodes should be defined such that at any time, $t$, if an observation is observed at time $t + 1$ they receive a 1 and a 0 otherwise.

**Note: Censoring nodes must be provided if there are missing outcomes.**

```{r}
# all observations that were observed through time 1
head(sim_cens[sim_cens$C1 == 1, ])

# all observations censored after time 1
head(sim_cens[sim_cens$C1 == 0, ])

# all observations censored after time 2
head(sim_cens[sim_cens$C2 == 0, ])
```

```{r}
# estimating an effect when there is censoring
a <- c("A1", "A2")
nodes <- list(c("L1"), c("L2"))
cens <- c("C1", "C2")

lmtp_tmle(sim_cens, a, "Y", time_vary = nodes, cens = cens, k = 0, 
          shift = function(data, trt) data[[trt]] + 0.5)
```

### Survival analysis

Time-to-event analyses are supported for both time-invariant and time-varying exposures. The `outcome` argument should be provided a vector containing the names of intermediate outcome variables as well as the final outcome variable. This means that if the `time_vary` argument is supplied a list of length $\tau$ then the length of the vector supplied to the `outcome` argument should be of length $\tau + 1$. 

For time-to-event problems, the intermediate outcome variables serve as indicators for when an observation experiences the event before the end of follow-up. If an observation does experience the event before the final outcome time, all future outcome variables (including the final outcome) variable should be set to 1. The function `event_locf()` (last observation carried forward, only for events) is provided to help with this imputation. 

The following example shows how to estimate the cumulative incidence of an event at time $\tau + 1 = 7$ under a hypothetical intervention where all subjects point treatment is set to 1.  

```{r warning = FALSE}
head(sim_point_surv)

a <- "trt"
y <- paste0("Y.", 1:6)
cens <- paste0("C.", 0:5)
baseline <- c("W1", "W2")
lmtp_tmle(sim_point_surv, a, y, baseline, cens = cens, 
          shift = static_binary_on, folds = 2)
```

#### Population mean outcome

In certain situations, the user may be interested in the population mean outcome under no intervention. In the presence of censoring, this can be estimated by setting `shift = NULL` and providing censoring indicators. 

```{r}
a <- c("A1", "A2")
nodes <- list(c("L1"), c("L2"))
cens <- c("C1", "C2")

lmtp_tmle(sim_cens, a, "Y", time_vary = nodes, cens = cens, k = 0, shift = NULL)
```

### Calculating contrasts

The effects returned by `lmtp` estimators are population intervention effects, that is the expected mean outcome in the population under the hypothetical intervention. Often, however, we are also interested in the comparison of different interventions to each other or to no intervention at all. This is the role of `lmtp_contrast()`. 

```{r}
a <- c("A1", "A2")
nodes <- list(c("L1"), c("L2"))
cens <- c("C1", "C2")

fit_shift <- 
  lmtp_tmle(sim_cens, a, "Y", time_vary = nodes, cens = cens, k = 0, 
            shift = function(data, trt) data[[trt]] + 0.5, folds = 2)

fit_noshift <- 
  lmtp_tmle(sim_cens, a, "Y", time_vary = nodes, cens = cens, k = 0, 
            shift = NULL, folds = 2)

lmtp_contrast(fit_shift, ref = fit_noshift, type = "additive")
lmtp_contrast(fit_shift, ref = fit_noshift, type = "rr")
```

Any number of `lmtp` fits can specified in `lmtp_contrast()` to be compared to either a single reference fit or a known scalar. 

```{r}
lmtp_contrast(fit_shift, fit_noshift, ref = 0.787)
```

### Bootstrap for G-comp & IPW

There is no theory to provide standard errors for the G-computation or IPW estimators when using data-adaptive estimation procedures such as the super learner; standard errors are thus not provided. However, if using a pre-specified parametric model for estimation, inference can be performed using the non-parametric bootstrap.

## Extra features

> The goal of this section is to identify extra features supported by `lmtp` that can improve the user experience. 

### Tidy results

`lmtp` automatically provides a `tidy` method as described in the [`broom`](https://cran.r-project.org/web/packages/broom/index.html) package: 

```{r tidy}
a <- c("A_1", "A_2", "A_3", "A_4")
time_varying <- list(c("L_1"), c("L_2"), c("L_3"), c("L_4"))
shift <- function(data, trt) {
  (data[[trt]] - 1) * (data[[trt]] - 1 >= 1) + data[[trt]] * (data[[trt]] - 1 < 1)
}

fit <- lmtp_tmle(sim_t4, a, "Y", time_vary = time_varying, k = 0, shift = shift, folds = 2)

tidy(fit)
```

### Parallel processing with future

Computation time can quickly increase in situations with lots of time points, complex ensemble learners, and large datasets. In response, `lmtp` provides support for parallel processing using the [`future`](https://cran.r-project.org/web/packages/future/index.html) package. The simplest way to use `lmtp` estimators in parallel is to run `plan(multiprocess)`. We recommend consulting the `future` [documentation](https://cran.r-project.org/web/packages/future/future.pdf) for more information.

### Progress bars with progressr

In the presence of long computation time, a lack of user feedback can become very frustrating. To address this, `lmtp` supports the use of progress bars during computation through the [`progressr`](https://cran.r-project.org/web/packages/progressr/index.html) package.

```{r, eval = F}
library(progressr)

with_progress({
  fit <- lmtp_tmle(...)
})
```

We recommend consulting the `progressr` [documentation](https://cran.r-project.org/web/packages/progressr/progressr.pdf) for more information. 

## References

Díaz I, Williams N, Hoffman KL, Schenck, EJ (2020). Non-Parametric Causal Effects Based on Longitudinal Modified Policies. arXiv: https://arxiv.org/abs/2006.01366v2

Díaz Muñoz, I. and van der Laan, M. (2012). Population Intervention Causal Effects Based on Stochastic Interventions. Biometrics, 68: 541-549. doi:10.1111/j.1541-0420.2011.01685.x

Haneuse, S. and Rotnitzky, A. (2013), Estimation of the effect of interventions that modify the received treatment. Statist. Med., 32: 5260-5277. doi:10.1002/sim.5907

Coyle JR, Hejazi NS, Malenica I, Sofrygin O (2020). _sl3: Pipelines for
Machine Learning and Super Learning_. doi: 10.5281/zenodo.1342293 (URL:
https://doi.org/10.5281/zenodo.1342293), R package version 1.3.8, <URL:
https://github.com/tlverse/sl3>.
